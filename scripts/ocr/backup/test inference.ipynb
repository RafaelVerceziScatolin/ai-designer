{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e11b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import pandas\n",
    "import numpy\n",
    "from torch_geometric.data import Data\n",
    "sys.path.append(\"D:\\orguel_ml_library\")\n",
    "from orguel_ml import Graph as BaseGraph\n",
    "\n",
    "class Graph(BaseGraph):\n",
    "    __edge_attributes = {\n",
    "                            \"parallel\": 0,\n",
    "                            \"colinear\": 0,\n",
    "                            \"perpendicular_distance\": 0,\n",
    "                            \"overlap_ratio\": 0,\n",
    "                            \"point_intersection\": 0,\n",
    "                            \"segment_intersection\": 0,\n",
    "                            \"angle_difference\": 0\n",
    "                        }\n",
    "    def __init__(self, dataframe):\n",
    "        self.__dataframe = dataframe\n",
    "        \n",
    "        coordinates_x = dataframe[['start_x', 'end_x']]\n",
    "        coordinates_y = dataframe[['start_y', 'end_y']]\n",
    "        \n",
    "        normalizedCoordinates = dataframe[['start_x', 'start_y', 'end_x', 'end_y']].copy()\n",
    "        normalizedCoordinates[['start_x', 'end_x']] = (normalizedCoordinates[['start_x', 'end_x']] - coordinates_x.values.mean()) / coordinates_x.values.std()\n",
    "        normalizedCoordinates[['start_y', 'end_y']] = (normalizedCoordinates[['start_y', 'end_y']] - coordinates_y.values.mean()) / coordinates_y.values.std()\n",
    "        \n",
    "        normalizedAngles = numpy.column_stack((numpy.sin(dataframe['angle']), numpy.cos(dataframe['angle'])))\n",
    "        normalizedLengths = dataframe[['length']] / 176.53671467337412\n",
    "        \n",
    "        self.nodesAttributes = numpy.hstack([normalizedCoordinates.values, normalizedAngles, normalizedLengths.values])\n",
    "        self.edges: List[Tuple[int, int]] = []\n",
    "        self.edgesAttributes: List[List[float]] = []\n",
    "\n",
    "def CreateGraph(dataframe):\n",
    "    # Calculate length, angle, and offset\n",
    "    def Length(row):\n",
    "        return ((row[\"end_x\"] - row[\"start_x\"])**2 + (row[\"end_y\"] - row[\"start_y\"])**2) ** 0.5\n",
    "    \n",
    "    def Angle(row):\n",
    "        return math.atan2(row[\"end_y\"] - row[\"start_y\"], row[\"end_x\"] - row[\"start_x\"]) % math.pi\n",
    "    \n",
    "    def Offset(row):\n",
    "        nlen = math.hypot(row[\"start_y\"] - row[\"end_y\"], row[\"end_x\"] - row[\"start_x\"])\n",
    "        if nlen < 1e-12: return 0.0\n",
    "        return abs(row[\"start_x\"] * ((row[\"start_y\"] - row[\"end_y\"]) / nlen) +\n",
    "                   row[\"start_y\"] * ((row[\"end_x\"] - row[\"start_x\"]) / nlen))\n",
    "    \n",
    "    dataframe[\"length\"] = dataframe.apply(Length, axis=1)\n",
    "    dataframe[\"angle\"] = dataframe.apply(Angle, axis=1)\n",
    "    dataframe[\"offset\"] = dataframe.apply(Offset, axis=1)\n",
    "    \n",
    "    graph = Graph(dataframe)\n",
    "    graph.ParallelDetection()\n",
    "    graph.IntersectionDetection()\n",
    "    \n",
    "    graph.nodesAttributes = torch.tensor(graph.nodesAttributes, dtype=torch.float)\n",
    "    graph.edges = torch.tensor(graph.edges, dtype=torch.long).t().contiguous()\n",
    "    graph.edgesAttributes = torch.tensor(graph.edgesAttributes, dtype=torch.float)\n",
    "    \n",
    "    return Data(x=graph.nodesAttributes, edge_index=graph.edges, edge_attr=graph.edgesAttributes, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5461a68",
   "metadata": {},
   "outputs": [],
   "source": [
    " # ✅ Step 1: Receive CSV string from AutoCAD\n",
    "csv_file = \"C:\\\\Users\\\\Rafael\\\\Desktop\\\\text_recognition\\\\database.csv\"\n",
    "\n",
    "dataframe = pandas.read_csv(csv_file, header=None)\n",
    "dataframe.columns = ['handle', 'start_x', 'start_y', 'end_x', 'end_y']\n",
    "\n",
    "for col in ['circle','arc','radius','start_angle','end_angle','layer']:\n",
    "    dataframe[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Step 2: Convert CSV string into a graph\n",
    "graph: Data = CreateGraph(dataframe)  # Convert AutoCAD data into a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265fc3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael\\AppData\\Local\\Temp\\ipykernel_19904\\2248256639.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r\"C:\\Users\\Rafael\\Desktop\\text_recognition\\OCRNetwork.pt\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OCRNetwork(\n",
       "  (embedding_layer): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (conv1): NNConv(64, 128, aggr=add, nn=Sequential(\n",
       "    (0): Linear(in_features=7, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=8192, bias=True)\n",
       "  ))\n",
       "  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (conv2): NNConv(128, 32, aggr=add, nn=Sequential(\n",
       "    (0): Linear(in_features=7, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=4096, bias=True)\n",
       "  ))\n",
       "  (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cluster_embedding): Embedding(118, 32)\n",
       "  (character_head): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=118, bias=True)\n",
       "  )\n",
       "  (font_head): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (regression_head): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from orguel_ml.ocr import OCRNetwork\n",
    "\n",
    "# ✅ Step 3: Load trained GNN model\n",
    "model = OCRNetwork()\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\Rafael\\Desktop\\text_recognition\\OCRNetwork.pt\", map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fcb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    output = model(graph)\n",
    "    char_pred = output[\"character_logits\"].argmax(dim=1).tolist()\n",
    "    font_pred = output[\"font_logits\"].argmax(dim=1).tolist()\n",
    "    height, rotation, insertion_x, insertion_y = output[\"regression_values\"].T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1431af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "for idx, handle in enumerate(dataframe['handle']):\n",
    "    print(f\"Line {handle} → char={char_pred[idx]}, font={font_pred[idx]}, height={height[idx]:.2f}, rot={rotation[idx]:.2f}, ins=({insertion_x[idx]:.2f}, {insertion_y[idx]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf84c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9,\n",
       " 'K': 10,\n",
       " 'L': 11,\n",
       " 'M': 12,\n",
       " 'N': 13,\n",
       " 'O': 14,\n",
       " 'P': 15,\n",
       " 'Q': 16,\n",
       " 'R': 17,\n",
       " 'S': 18,\n",
       " 'T': 19,\n",
       " 'U': 20,\n",
       " 'V': 21,\n",
       " 'W': 22,\n",
       " 'X': 23,\n",
       " 'Y': 24,\n",
       " 'Z': 25,\n",
       " 'a': 26,\n",
       " 'b': 27,\n",
       " 'c': 28,\n",
       " 'd': 29,\n",
       " 'e': 30,\n",
       " 'f': 31,\n",
       " 'g': 32,\n",
       " 'h': 33,\n",
       " 'i': 34,\n",
       " 'j': 35,\n",
       " 'k': 36,\n",
       " 'l': 37,\n",
       " 'm': 38,\n",
       " 'n': 39,\n",
       " 'o': 40,\n",
       " 'p': 41,\n",
       " 'q': 42,\n",
       " 'r': 43,\n",
       " 's': 44,\n",
       " 't': 45,\n",
       " 'u': 46,\n",
       " 'v': 47,\n",
       " 'w': 48,\n",
       " 'x': 49,\n",
       " 'y': 50,\n",
       " 'z': 51,\n",
       " '0': 52,\n",
       " '1': 53,\n",
       " '2': 54,\n",
       " '3': 55,\n",
       " '4': 56,\n",
       " '5': 57,\n",
       " '6': 58,\n",
       " '7': 59,\n",
       " '8': 60,\n",
       " '9': 61,\n",
       " '!': 62,\n",
       " '\"': 63,\n",
       " '#': 64,\n",
       " '$': 65,\n",
       " '%': 66,\n",
       " '&': 67,\n",
       " \"'\": 68,\n",
       " '*': 69,\n",
       " '+': 70,\n",
       " ',': 71,\n",
       " '-': 72,\n",
       " '.': 73,\n",
       " '/': 74,\n",
       " ':': 75,\n",
       " ';': 76,\n",
       " '=': 77,\n",
       " '?': 78,\n",
       " '@': 79,\n",
       " '\\\\': 80,\n",
       " '_': 81,\n",
       " '`': 82,\n",
       " '|': 83,\n",
       " '~': 84,\n",
       " '(': 85,\n",
       " ')': 86,\n",
       " '[': 87,\n",
       " ']': 88,\n",
       " '{': 89,\n",
       " '}': 90,\n",
       " '<': 91,\n",
       " '>': 92,\n",
       " 'À': 93,\n",
       " 'Á': 94,\n",
       " 'Â': 95,\n",
       " 'Ã': 96,\n",
       " 'Ç': 97,\n",
       " 'É': 98,\n",
       " 'Ê': 99,\n",
       " 'Í': 100,\n",
       " 'Ó': 101,\n",
       " 'Ô': 102,\n",
       " 'Ø': 103,\n",
       " 'Ú': 104,\n",
       " 'à': 105,\n",
       " 'á': 106,\n",
       " 'â': 107,\n",
       " 'ã': 108,\n",
       " 'ç': 109,\n",
       " 'é': 110,\n",
       " 'ê': 111,\n",
       " 'í': 112,\n",
       " 'ó': 113,\n",
       " 'ô': 114,\n",
       " '÷': 115,\n",
       " 'ø': 116,\n",
       " 'ú': 117}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from orguel_ml.ocr import character_set\n",
    "\n",
    "character_set[\"characters\"][\"encoding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c994f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
